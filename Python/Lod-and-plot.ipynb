{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.clear_all_output();\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.clear_all_output();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "from IPython import get_ipython\n",
    "get_ipython().magic('reset -sf')\n",
    "\n",
    "%who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.6.10 |Anaconda, Inc.| (default, Mar 23 2020, 23:13:11) \n",
      "[GCC 7.3.0]\n",
      "Version info.:  sys.version_info(major=3, minor=6, micro=10, releaselevel='final', serial=0)\n",
      "TensorFlow version:  2.1.0\n",
      "TensorFlow.Keras version :  2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import shutil\n",
    "import imgaug as aug\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mimg\n",
    "import imgaug.augmenters as iaa\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2\n",
    "# from keras import backend as K\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "os.environ['AUTOGRAPH_VERBOSITY'] = \"10\"\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.compat.v1.logging.set_verbosity(0)\n",
    "\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "print(\"Python version: \", sys.version)\n",
    "print(\"Version info.: \", sys.version_info)\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "print(\"TensorFlow.Keras version : \", tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0\n",
      "/job:localhost/replica:0/task:0/device:GPU:1 -> device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0\n",
      "/job:localhost/replica:0/task:0/device:GPU:2 -> device: 2, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0\n",
      "/job:localhost/replica:0/task:0/device:GPU:3 -> device: 3, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:1 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:2 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:3 -> device: XLA_GPU device\n",
      "\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--\n",
      "Number of devices: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Turn interactive plotting off\n",
    "# plt.ioff()\n",
    "# Set the seed for hash based operations in python\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# Set the numpy seed\n",
    "np.random.seed(111)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement = True\n",
    "config.gpu_options.visible_device_list='0,1,2,3'\n",
    "\n",
    "# Set the random seed in tensorflow at graph level\n",
    "tf.compat.v1.set_random_seed(111)\n",
    "\n",
    "# Set the session in tensorflow\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "# Set the session in keras\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "\n",
    "print(\"#--#--\"*10)\n",
    "print('Number of devices: {}\\n'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())\n",
    "\n",
    "# Make the augmentation sequence deterministic\n",
    "aug.seed(111)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "File time:  04-15-2020-16-45 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FileTime = str(datetime.datetime.now().strftime(\"%m-%d-%Y-%H-%M\"))\n",
    "FileTime = '04-15-2020-16-45'\n",
    "print(\"#--#--\"*10, \"\\nFile time: \", FileTime, \"\\n\\n\")\n",
    "\n",
    "# Define path to the data directory\n",
    "data_dir = Path('/data/user/tr27p/Courses/CS765-DeepLearning/FinalProject/Chest_X-Ray_Images_Pneumonia/Data/chest_xray/chest_xray/')\n",
    "\n",
    "# Path to train directory (Fancy pathlib...no more os.path!!)\n",
    "train_dir = data_dir / 'train'\n",
    "\n",
    "# Path to validation directory\n",
    "val_dir = data_dir / 'val'\n",
    "\n",
    "# Path to test directory\n",
    "test_dir = data_dir / 'test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "\n",
      "                                                image  label\n",
      "0  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      0\n",
      "1  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      0\n",
      "2  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      1\n",
      "3  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      1\n",
      "4  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      1\n"
     ]
    }
   ],
   "source": [
    "# Get the path to the normal and pneumonia sub-directories\n",
    "normal_cases_dir = train_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = train_dir / 'PNEUMONIA'\n",
    "\n",
    "# Get the list of all the images\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "# An empty list. We will insert the data into this list in (img_path, label) format\n",
    "train_data = []\n",
    "\n",
    "# Go through all the normal cases. The label for these cases will be 0\n",
    "for img in sorted(normal_cases):\n",
    "    train_data.append((img,0))\n",
    "\n",
    "# Go through all the pneumonia cases. The label for these cases will be 1\n",
    "for img in sorted(pneumonia_cases):\n",
    "    train_data.append((img, 1))\n",
    "\n",
    "# Get a pandas dataframe from the data we have in our list\n",
    "train_data = pd.DataFrame(train_data, columns=['image', 'label'],index=None)\n",
    "\n",
    "# Shuffle the data\n",
    "train_data = train_data.sample(random_state=111, frac=1.).reset_index(drop=True)\n",
    "# train_data = train_data.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "# How the dataframe looks like?\n",
    "print(\"#--#--\"*10,\"\\n\\n\",train_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    3875\n",
      "0    1341\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get the counts for each class\n",
    "cases_count = train_data['label'].value_counts()\n",
    "print(cases_count)\n",
    "\n",
    "# Plot the results\n",
    "# plt.figure(figsize=(10,8))\n",
    "# sns.barplot(x=cases_count.index, y= cases_count.values)\n",
    "# plt.title('Number of cases', fontsize=14)\n",
    "# plt.xlabel('Case type', fontsize=12)\n",
    "# plt.ylabel('Count', fontsize=12)\n",
    "# plt.xticks(range(len(cases_count.index)), ['Normal(0)', 'Pneumonia(1)'])\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get few samples for both the classes\n",
    "pneumonia_samples = (train_data[train_data['label']==1]['image'].iloc[:5]).tolist()\n",
    "normal_samples = (train_data[train_data['label']==0]['image'].iloc[:5]).tolist()\n",
    "\n",
    "# Concat the data in a single list and del the above two list\n",
    "samples = pneumonia_samples + normal_samples\n",
    "del pneumonia_samples, normal_samples\n",
    "\n",
    "# Plot the data\n",
    "# f, ax = plt.subplots(2,5, figsize=(30,10))\n",
    "# for i in range(10):\n",
    "#     img = imread(samples[i])\n",
    "#     ax[i//5, i%5].imshow(img, cmap='gray')\n",
    "#     if i<5:\n",
    "#         ax[i//5, i%5].set_title(\"Pneumonia\")\n",
    "#     else:\n",
    "#         ax[i//5, i%5].set_title(\"Normal\")\n",
    "#     ax[i//5, i%5].axis('off')\n",
    "#     ax[i//5, i%5].set_aspect('auto')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "\n",
      "                                                image  label\n",
      "0  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      1\n",
      "1  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      0\n",
      "2  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      0\n",
      "3  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      1\n",
      "4  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      0\n"
     ]
    }
   ],
   "source": [
    "# Get the path to the sub-directories\n",
    "normal_cases_dir = val_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = val_dir / 'PNEUMONIA'\n",
    "\n",
    "# Get the list of all the images\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "# List that are going to contain validation images data and the corresponding labels\n",
    "# An empty list. We will insert the data into this list in (img_path, label) format\n",
    "valid_data = []\n",
    "\n",
    "\n",
    "# Go through all the normal cases. The label for these cases will be 0\n",
    "for img in sorted(normal_cases):\n",
    "    valid_data.append((img,0))\n",
    "\n",
    "# Go through all the pneumonia cases. The label for these cases will be 1\n",
    "for img in sorted(pneumonia_cases):\n",
    "    valid_data.append((img, 1))\n",
    "\n",
    "# Get a pandas dataframe from the data we have in our list\n",
    "valid_data = pd.DataFrame(valid_data, columns=['image', 'label'],index=None)\n",
    "\n",
    "# Shuffle the data\n",
    "valid_data = valid_data.sample(random_state=111, frac=1.).reset_index(drop=True)\n",
    "# train_data = train_data.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "# How the dataframe looks like?\n",
    "print(\"#--#--\"*10,\"\\n\\n\",valid_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation sequence\n",
    "seq = iaa.OneOf([\n",
    "    iaa.Fliplr(), # horizontal flips\n",
    "    iaa.Affine(rotate=20), # roatation\n",
    "    iaa.Multiply((1.2, 1.5))]) #random brightness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(data, batch_size, augment=False):\n",
    "    # Get total number of samples in the data\n",
    "    n = len(data)\n",
    "    steps = n//batch_size\n",
    "\n",
    "    # Define two numpy arrays for containing batch data and labels\n",
    "    batch_data = np.zeros((batch_size, 224, 224, 3), dtype=np.float32)\n",
    "    batch_labels = np.zeros((batch_size,2), dtype=np.float32)\n",
    "\n",
    "    # Get a numpy array of all the indices of the input data\n",
    "    indices = np.arange(n)\n",
    "\n",
    "    # Initialize a counter\n",
    "    i =0\n",
    "    while True:\n",
    "#         np.random.shuffle(indices)\n",
    "        # Get the next batch\n",
    "        count = 0\n",
    "        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n",
    "        for j, idx in enumerate(next_batch):\n",
    "            img_name = data.iloc[idx]['image']\n",
    "            label = data.iloc[idx]['label']\n",
    "#             print(\"IMG-NAME: \", str(img_name).split(\"/\")[-1])\n",
    "            # one hot encoding\n",
    "            encoded_label = to_categorical(label, num_classes=2)\n",
    "            # read the image and resize\n",
    "            img = cv2.imread(str(img_name))\n",
    "            img = cv2.resize(img, (224,224))\n",
    "\n",
    "            # check if it's grayscale\n",
    "            if img.shape[2]==1:\n",
    "                img = np.dstack([img, img, img])\n",
    "\n",
    "            # cv2 reads in BGR mode by default\n",
    "            orig_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            # normalize the image pixels\n",
    "            orig_img = img.astype(np.float32)/255.\n",
    "\n",
    "            batch_data[count] = orig_img\n",
    "            batch_labels[count] = encoded_label\n",
    "\n",
    "\n",
    "#             count+=1\n",
    "            # generating more samples of the undersampled class\n",
    "            if augment:\n",
    "                if label==0 and count < batch_size-2:\n",
    "                    aug_img1 = seq.augment_image(img)\n",
    "                    aug_img2 = seq.augment_image(img)\n",
    "                    aug_img1 = cv2.cvtColor(aug_img1, cv2.COLOR_BGR2RGB)\n",
    "                    aug_img2 = cv2.cvtColor(aug_img2, cv2.COLOR_BGR2RGB)\n",
    "                    aug_img1 = aug_img1.astype(np.float32)/255.\n",
    "                    aug_img2 = aug_img2.astype(np.float32)/255.\n",
    "\n",
    "                    batch_data[count+1] = aug_img1\n",
    "                    batch_labels[count+1] = encoded_label\n",
    "                    batch_data[count+2] = aug_img2\n",
    "                    batch_labels[count+2] = encoded_label\n",
    "                    count +=2\n",
    "\n",
    "                else:\n",
    "                    count+=1\n",
    "            else:\n",
    "                count+=1\n",
    "\n",
    "            if count==batch_size:\n",
    "                break\n",
    "\n",
    "        i+=1\n",
    "        yield (batch_data, batch_labels)\n",
    "\n",
    "        if i>=steps:\n",
    "            i=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a =  data_gen(data=train_data, batch_size=16)\n",
    "# for x, y in a:\n",
    "#     for img, lab in zip(x,y):\n",
    "#         plt.title(lab)\n",
    "#         plt.imshow(img, cmap='gray')\n",
    "#         plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_img = Input(shape=(224,224,3), name='ImageInput')\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_1')(input_img)\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool1')(x)\n",
    "\n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_1')(x)\n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool2')(x)\n",
    "\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_1')(x)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool3')(x)\n",
    "\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_1')(x)\n",
    "    x = BatchNormalization(name='bn3')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_2')(x)\n",
    "    x = BatchNormalization(name='bn4')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool4')(x)\n",
    "\n",
    "    # x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv5_1')(x)\n",
    "    # x = BatchNormalization(name='bn5')(x)\n",
    "    # x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv5_2')(x)\n",
    "    # x = BatchNormalization(name='bn6')(x)\n",
    "    # x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv5_3')(x)\n",
    "    # x = MaxPooling2D((2,2), name='pool5')(x)\n",
    "\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.7, name='dropout1')(x)\n",
    "    x = Dense(512, activation='relu', name='fc2')(x)\n",
    "    x = Dropout(0.5, name='dropout2')(x)\n",
    "    x = Dense(2, activation='softmax', name='fc3')(x)\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model =  build_model()\n",
    "    # opt = RMSprop(lr=1e-4, clipnorm=1.)\n",
    "    opt = Adam(lr=1e-4, amsgrad=True, clipnorm=1.)\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC()],optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ImageInput (InputLayer)      [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "Conv1_1 (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "Conv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "Conv2_1 (SeparableConv2D)    (None, 112, 112, 128)     8896      \n",
      "_________________________________________________________________\n",
      "Conv2_2 (SeparableConv2D)    (None, 112, 112, 128)     17664     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "Conv3_1 (SeparableConv2D)    (None, 56, 56, 256)       34176     \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Conv3_2 (SeparableConv2D)    (None, 56, 56, 256)       68096     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Conv3_3 (SeparableConv2D)    (None, 56, 56, 256)       68096     \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "Conv4_1 (SeparableConv2D)    (None, 28, 28, 512)       133888    \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv4_2 (SeparableConv2D)    (None, 28, 28, 512)       267264    \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv4_3 (SeparableConv2D)    (None, 28, 28, 512)       267264    \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 104,197,506\n",
      "Trainable params: 104,194,434\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with strategy.scope():\n",
    "#     # Open the VGG16 weight file\n",
    "#     f = h5py.File('/data/user/tr27p/Courses/CS765-DeepLearning/FinalProject/Chest_X-Ray_Images_Pneumonia/Data/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', 'r')\n",
    "\n",
    "#     # Select the layers for which you want to set weight.\n",
    "\n",
    "#     w,b = f['block1_conv1']['block1_conv1_W_1:0'], f['block1_conv1']['block1_conv1_b_1:0']\n",
    "#     model.layers[1].set_weights = [w,b]\n",
    "\n",
    "#     w,b = f['block1_conv2']['block1_conv2_W_1:0'], f['block1_conv2']['block1_conv2_b_1:0']\n",
    "#     model.layers[2].set_weights = [w,b]\n",
    "\n",
    "#     w,b = f['block2_conv1']['block2_conv1_W_1:0'], f['block2_conv1']['block2_conv1_b_1:0']\n",
    "#     model.layers[4].set_weights = [w,b]\n",
    "\n",
    "#     w,b = f['block2_conv2']['block2_conv2_W_1:0'], f['block2_conv2']['block2_conv2_b_1:0']\n",
    "#     model.layers[5].set_weights = [w,b]\n",
    "\n",
    "# f.close()\n",
    "# print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback for printing the LR at the end of each epoch.\n",
    "class PrintLR(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print('\\nLearning rate for epoch {} is {}\\n'.format(epoch + 1, model.optimizer.lr.numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "\n",
      "Number of training and validation steps: 16 and 0\n"
     ]
    }
   ],
   "source": [
    "# batch_size = 16\n",
    "nb_epochs = 20\n",
    "BUFFER_SIZE = len(train_data)\n",
    "\n",
    "BATCH_SIZE_PER_REPLICA = 80\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "batch_size = BATCH_SIZE\n",
    "\n",
    "callbacks = [\n",
    "#     tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "    ReduceLROnPlateau(monitor='val_auc', factor=.5, patience=3, verbose=1, mode='max'),\n",
    "    # EarlyStopping(  monitor='val_loss', min_delta=1e-3, patience=5, verbose=1,\n",
    "    #                 mode='auto', baseline=None, restore_best_weights=True),\n",
    "    ModelCheckpoint(filepath='/data/user/tr27p/Courses/CS765-DeepLearning/FinalProject/Chest_X-Ray_Images_Pneumonia/Python/best_model_todate_python/'+FileTime+'/',\n",
    "                    monitor='val_auc', verbose=1,\n",
    "                    save_best_only=True, save_weights_only=True),\n",
    "    PrintLR()\n",
    "]\n",
    "\n",
    "# Get a train data generator\n",
    "train_data_gen = data_gen(data=train_data, batch_size=batch_size)\n",
    "\n",
    "# Get a valid data generator\n",
    "val_data_gen = data_gen(data=valid_data, batch_size=batch_size)\n",
    "\n",
    "# Define the number of training steps\n",
    "nb_train_steps = train_data.shape[0]//batch_size\n",
    "\n",
    "# Define the number of validation steps\n",
    "nb_valid_steps = valid_data.shape[0]//batch_size\n",
    "\n",
    "print(\"#--#--\"*10,\"\\n\\nNumber of training and validation steps: {} and {}\".format(nb_train_steps, nb_valid_steps))#len(valid_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      " BATCH_SIZE_PER_REPLICA =  80 \n",
      " BATCH_SIZE =  320 \n",
      " EPOCHS =  20\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--\n",
      "Optimizer :\n",
      "           name : Adam\n",
      "       clipnorm : 1.0\n",
      "  learning_rate : 0.0001\n",
      "          decay : 0.0\n",
      "         beta_1 : 0.9\n",
      "         beta_2 : 0.999\n",
      "        epsilon : 1e-07\n",
      "        amsgrad : True\n",
      "\n",
      "Reduce LR On Plateau :\n",
      "        Monitor : val_auc,\n",
      "         Factor : 0.5,\n",
      "           Mode : max,\n",
      "       Patience : 3\n"
     ]
    }
   ],
   "source": [
    "# print(\"#--#--\"*10,  \"\\n UPDATED MODEL BASED ON VGG16\")\n",
    "\n",
    "print(\"#--#--\"*10,  \"\\n BATCH_SIZE_PER_REPLICA = \", BATCH_SIZE_PER_REPLICA,\n",
    "                    \"\\n BATCH_SIZE = \", BATCH_SIZE,\n",
    "                    \"\\n EPOCHS = \", nb_epochs)\n",
    "\n",
    "def print_inventory(inventory_name, dct):\n",
    "    print('%s :' %(inventory_name))\n",
    "    for item, amount in dct.items():  # dct.iteritems() in Python 2\n",
    "        print('%15s : %s' % (item, amount))\n",
    "\n",
    "print(\"#--#--\"*10)\n",
    "print_inventory(\"Optimizer\", opt.get_config())\n",
    "# print(\"#--#--\"*10)\n",
    "# print_inventory(\"Early Stopping\", opt.get_config())\n",
    "# print(\"#--#--\"*10)\n",
    "# print_inventory(\"Reduce LR On Plateau\", opt.get_config())\n",
    "\n",
    "print('\\nReduce LR On Plateau :\\n%15s : %s,\\n%15s : %s,\\n%15s : %s,\\n%15s : %s' %  ('Monitor', callbacks[0].monitor,\n",
    "                                                                                    'Factor', callbacks[0].factor,\n",
    "                                                                                    'Mode', callbacks[0].mode,\n",
    "                                                                                    'Patience', callbacks[0].patience) )\n",
    "\n",
    "# print('\\n Early Stopping:\\n%15s : %s,\\n%15s : %s,\\n%15s : %s' %('Monitor', callbacks[1].monitor,\n",
    "#                                                                 'MinDelta', callbacks[1].min_delta,\n",
    "#                                                                 'patience', callbacks[1].patience) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightPath = '/data/user/tr27p/Courses/CS765-DeepLearning/FinalProject/Chest_X-Ray_Images_Pneumonia/Python/xray-best-model/best_model/best_model_para-tune_'+FileTime+'.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "\n",
      "weightPath:  /data/user/tr27p/Courses/CS765-DeepLearning/FinalProject/Chest_X-Ray_Images_Pneumonia/Python/xray-best-model/best_model/best_model_para-tune_04-15-2020-16-45.hdf5\n"
     ]
    }
   ],
   "source": [
    "print(\"#--#--\"*10,\"\\n\\nweightPath: \", weightPath)\n",
    "\n",
    "with strategy.scope():\n",
    "    model.load_weights(weightPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "\n",
      "Total number of test examples:  (624, 224, 224, 3)\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "\n",
      "Total number of labels: (624, 2)\n"
     ]
    }
   ],
   "source": [
    "# Preparing test data\n",
    "normal_cases_dir = test_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = test_dir / 'PNEUMONIA'\n",
    "\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "val_normal_cases_dir = val_dir / 'NORMAL'\n",
    "val_pneumonia_cases_dir = val_dir / 'PNEUMONIA'\n",
    "\n",
    "val_normal_cases = val_normal_cases_dir.glob('*.jpeg')\n",
    "val_pneumonia_cases = val_pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "train_normal_cases_dir = train_dir / 'NORMAL'\n",
    "train_pneumonia_cases_dir = train_dir / 'PNEUMONIA'\n",
    "\n",
    "train_normal_cases = train_normal_cases_dir.glob('*.jpeg')\n",
    "train_pneumonia_cases = train_pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "for img in normal_cases:\n",
    "    img = cv2.imread(str(img))\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    if img.shape[2] ==1:\n",
    "        img = np.dstack([img, img, img])\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)/255.\n",
    "    label = to_categorical(0, num_classes=2)\n",
    "    test_data.append(img)\n",
    "    test_labels.append(label)\n",
    "\n",
    "# for img in val_normal_cases:\n",
    "#     img = cv2.imread(str(img))\n",
    "#     img = cv2.resize(img, (224,224))\n",
    "#     if img.shape[2] ==1:\n",
    "#         img = np.dstack([img, img, img])\n",
    "#     else:\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     img = img.astype(np.float32)/255.\n",
    "#     label = to_categorical(0, num_classes=2)\n",
    "#     test_data.append(img)\n",
    "#     test_labels.append(label)\n",
    "    \n",
    "# for img in train_normal_cases:\n",
    "#     img = cv2.imread(str(img))\n",
    "#     img = cv2.resize(img, (224,224))\n",
    "#     if img.shape[2] ==1:\n",
    "#         img = np.dstack([img, img, img])\n",
    "#     else:\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     img = img.astype(np.float32)/255.\n",
    "#     label = to_categorical(0, num_classes=2)\n",
    "#     test_data.append(img)\n",
    "#     test_labels.append(label)\n",
    "    \n",
    "for img in pneumonia_cases:\n",
    "    img = cv2.imread(str(img))\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    if img.shape[2] ==1:\n",
    "        img = np.dstack([img, img, img])\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)/255.\n",
    "    label = to_categorical(1, num_classes=2)\n",
    "    test_data.append(img)\n",
    "    test_labels.append(label)\n",
    "\n",
    "# for img in val_pneumonia_cases:\n",
    "#     img = cv2.imread(str(img))\n",
    "#     img = cv2.resize(img, (224,224))\n",
    "#     if img.shape[2] ==1:\n",
    "#         img = np.dstack([img, img, img])\n",
    "#     else:\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     img = img.astype(np.float32)/255.\n",
    "#     label = to_categorical(1, num_classes=2)\n",
    "#     test_data.append(img)\n",
    "#     test_labels.append(label)\n",
    "    \n",
    "# for img in train_pneumonia_cases:\n",
    "#     img = cv2.imread(str(img))\n",
    "#     img = cv2.resize(img, (224,224))\n",
    "#     if img.shape[2] ==1:\n",
    "#         img = np.dstack([img, img, img])\n",
    "#     else:\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     img = img.astype(np.float32)/255.\n",
    "#     label = to_categorical(1, num_classes=2)\n",
    "#     test_data.append(img)\n",
    "#     test_labels.append(label)\n",
    "    \n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(\"#--#--\"*10,\"\\n\\nTotal number of test examples: \", test_data.shape)\n",
    "print(\"#--#--\"*10,\"\\n\\nTotal number of labels:\", test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 9s 15ms/sample - loss: 2.1136 - accuracy: 0.7516 - auc: 0.7963\n",
      "Loss on test set:  2.113645783183762\n",
      "Accuracy on test set:  0.7516026\n",
      "AUC on test set:  0.7963189\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on test dataset\n",
    "with strategy.scope():\n",
    "    test_loss, test_score, test_auc = model.evaluate(test_data, test_labels, batch_size=batch_size)\n",
    "print(\"Loss on test set: \", test_loss)\n",
    "print(\"Accuracy on test set: \", test_score)\n",
    "print(\"AUC on test set: \", test_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "\n",
      " (624,)\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "\n",
      " (624,)\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "with strategy.scope():\n",
    "    preds = model.predict(test_data, batch_size=batch_size)\n",
    "preds = np.argmax(preds, axis=-1)\n",
    "\n",
    "# Original labels\n",
    "orig_test_labels = np.argmax(test_labels, axis=-1)\n",
    "\n",
    "print(\"#--#--\"*10,\"\\n\\n\",orig_test_labels.shape)\n",
    "print(\"#--#--\"*10,\"\\n\\n\",preds.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the confusion matrix\n",
    "cm  = confusion_matrix(orig_test_labels, preds)\n",
    "fig = plt.figure()\n",
    "plot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
    "plt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "#plt.savefig(\"/data/user/tr27p/Courses/CS765-DeepLearning/FinalProject/Chest_X-Ray_Images_Pneumonia/Python/python_confusion-mat.png\", format='png')\n",
    "# plt.savefig('/data/user/tr27p/Courses/CS765-DeepLearning/FinalProject/Chest_X-Ray_Images_Pneumonia/Python/plots/confusion-mat/python_confusion-mat-'+FileTime+'.png', format='png')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "\n",
      "Recall of the model is 1.00\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "\n",
      "Precision of the model is 0.72\n"
     ]
    }
   ],
   "source": [
    "# Calculate Precision and Recall\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "print(\"#--#--\"*10,\"\\n\\nRecall of the model is {:.2f}\".format(recall))\n",
    "print(\"#--#--\"*10,\"\\n\\nPrecision of the model is {:.2f}\".format(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
