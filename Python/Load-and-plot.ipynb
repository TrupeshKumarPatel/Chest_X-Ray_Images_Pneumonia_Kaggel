{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.clear_all_output();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "from IPython import get_ipython\n",
    "get_ipython().magic('reset -sf')\n",
    "\n",
    "%who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.6.10 |Anaconda, Inc.| (default, Jan  7 2020, 21:14:29) \n",
      "[GCC 7.3.0]\n",
      "Version info.:  sys.version_info(major=3, minor=6, micro=10, releaselevel='final', serial=0)\n",
      "TensorFlow version:  2.1.0\n",
      "TensorFlow.Keras version :  2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import shutil\n",
    "import imgaug as aug\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mimg\n",
    "import imgaug.augmenters as iaa\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2\n",
    "# from keras import backend as K\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "os.environ['AUTOGRAPH_VERBOSITY'] = \"10\"\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.compat.v1.logging.set_verbosity(0)\n",
    "\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "print(\"Python version: \", sys.version)\n",
    "print(\"Version info.: \", sys.version_info)\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "print(\"TensorFlow.Keras version : \", tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0\n",
      "/job:localhost/replica:0/task:0/device:GPU:1 -> device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0\n",
      "/job:localhost/replica:0/task:0/device:GPU:2 -> device: 2, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0\n",
      "/job:localhost/replica:0/task:0/device:GPU:3 -> device: 3, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:1 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:2 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:3 -> device: XLA_GPU device\n",
      "\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--\n",
      "Number of devices: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Turn interactive plotting off\n",
    "# plt.ioff()\n",
    "# Set the seed for hash based operations in python\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# Set the numpy seed\n",
    "np.random.seed(111)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement = True\n",
    "config.gpu_options.visible_device_list='0,1,2,3'\n",
    "\n",
    "# Set the random seed in tensorflow at graph level\n",
    "tf.compat.v1.set_random_seed(111)\n",
    "\n",
    "# Set the session in tensorflow\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "# Set the session in keras\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "\n",
    "print(\"#--#--\"*10)\n",
    "print('Number of devices: {}\\n'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())\n",
    "\n",
    "# Make the augmentation sequence deterministic\n",
    "aug.seed(111)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "File time:  04-17-2020-15-13 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# FileTime = str(datetime.datetime.now().strftime(\"%m-%d-%Y-%H-%M\"))\n",
    "FileTime = '04-17-2020-15-13'\n",
    "print(\"#--#--\"*10, \"\\nFile time: \", FileTime, \"\\n\\n\")\n",
    "\n",
    "# Define path to the data directory\n",
    "data_dir = Path('/data/user/tr27p/Courses/CS765-DeepLearning/FinalProject/Chest_X-Ray_Images_Pneumonia/Data/chest_xray/chest_xray/')\n",
    "\n",
    "# Path to train directory (Fancy pathlib...no more os.path!!)\n",
    "train_dir = data_dir / 'train'\n",
    "\n",
    "# Path to validation directory\n",
    "val_dir = data_dir / 'val'\n",
    "\n",
    "# Path to test directory\n",
    "test_dir = data_dir / 'test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "\n",
      "                                                image  label\n",
      "0  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      0\n",
      "1  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      0\n",
      "2  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      1\n",
      "3  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      1\n",
      "4  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      1\n"
     ]
    }
   ],
   "source": [
    "# Get the path to the normal and pneumonia sub-directories\n",
    "normal_cases_dir = train_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = train_dir / 'PNEUMONIA'\n",
    "\n",
    "# Get the list of all the images\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "# An empty list. We will insert the data into this list in (img_path, label) format\n",
    "train_data = []\n",
    "\n",
    "# Go through all the normal cases. The label for these cases will be 0\n",
    "for img in sorted(normal_cases):\n",
    "    train_data.append((img,0))\n",
    "\n",
    "# Go through all the pneumonia cases. The label for these cases will be 1\n",
    "for img in sorted(pneumonia_cases):\n",
    "    train_data.append((img, 1))\n",
    "\n",
    "# Get a pandas dataframe from the data we have in our list\n",
    "train_data = pd.DataFrame(train_data, columns=['image', 'label'],index=None)\n",
    "\n",
    "# Shuffle the data\n",
    "train_data = train_data.sample(random_state=111, frac=1.).reset_index(drop=True)\n",
    "# train_data = train_data.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "# How the dataframe looks like?\n",
    "print(\"#--#--\"*10,\"\\n\\n\",train_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    3875\n",
      "0    1341\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get the counts for each class\n",
    "cases_count = train_data['label'].value_counts()\n",
    "print(cases_count)\n",
    "\n",
    "# Plot the results\n",
    "# plt.figure(figsize=(10,8))\n",
    "# sns.barplot(x=cases_count.index, y= cases_count.values)\n",
    "# plt.title('Number of cases', fontsize=14)\n",
    "# plt.xlabel('Case type', fontsize=12)\n",
    "# plt.ylabel('Count', fontsize=12)\n",
    "# plt.xticks(range(len(cases_count.index)), ['Normal(0)', 'Pneumonia(1)'])\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get few samples for both the classes\n",
    "pneumonia_samples = (train_data[train_data['label']==1]['image'].iloc[:5]).tolist()\n",
    "normal_samples = (train_data[train_data['label']==0]['image'].iloc[:5]).tolist()\n",
    "\n",
    "# Concat the data in a single list and del the above two list\n",
    "samples = pneumonia_samples + normal_samples\n",
    "del pneumonia_samples, normal_samples\n",
    "\n",
    "# Plot the data\n",
    "# f, ax = plt.subplots(2,5, figsize=(30,10))\n",
    "# for i in range(10):\n",
    "#     img = imread(samples[i])\n",
    "#     ax[i//5, i%5].imshow(img, cmap='gray')\n",
    "#     if i<5:\n",
    "#         ax[i//5, i%5].set_title(\"Pneumonia\")\n",
    "#     else:\n",
    "#         ax[i//5, i%5].set_title(\"Normal\")\n",
    "#     ax[i//5, i%5].axis('off')\n",
    "#     ax[i//5, i%5].set_aspect('auto')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "\n",
      "                                                image  label\n",
      "0  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      1\n",
      "1  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      0\n",
      "2  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      0\n",
      "3  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      1\n",
      "4  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      0\n"
     ]
    }
   ],
   "source": [
    "# Get the path to the sub-directories\n",
    "normal_cases_dir = val_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = val_dir / 'PNEUMONIA'\n",
    "\n",
    "# Get the list of all the images\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "# List that are going to contain validation images data and the corresponding labels\n",
    "# An empty list. We will insert the data into this list in (img_path, label) format\n",
    "valid_data = []\n",
    "\n",
    "\n",
    "# Go through all the normal cases. The label for these cases will be 0\n",
    "for img in sorted(normal_cases):\n",
    "    valid_data.append((img,0))\n",
    "\n",
    "# Go through all the pneumonia cases. The label for these cases will be 1\n",
    "for img in sorted(pneumonia_cases):\n",
    "    valid_data.append((img, 1))\n",
    "\n",
    "# Get a pandas dataframe from the data we have in our list\n",
    "valid_data = pd.DataFrame(valid_data, columns=['image', 'label'],index=None)\n",
    "\n",
    "# Shuffle the data\n",
    "valid_data = valid_data.sample(random_state=111, frac=1.).reset_index(drop=True)\n",
    "# train_data = train_data.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "# How the dataframe looks like?\n",
    "print(\"#--#--\"*10,\"\\n\\n\",valid_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation sequence\n",
    "seq = iaa.OneOf([\n",
    "    iaa.Fliplr(), # horizontal flips\n",
    "    iaa.Affine(rotate=20), # roatation\n",
    "    iaa.Multiply((1.2, 1.5))]) #random brightness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(data, batch_size, augment=False):\n",
    "    # Get total number of samples in the data\n",
    "    n = len(data)\n",
    "    steps = n//batch_size\n",
    "\n",
    "    # Define two numpy arrays for containing batch data and labels\n",
    "    batch_data = np.zeros((batch_size, 224, 224, 3), dtype=np.float32)\n",
    "    batch_labels = np.zeros((batch_size,2), dtype=np.float32)\n",
    "\n",
    "    # Get a numpy array of all the indices of the input data\n",
    "    indices = np.arange(n)\n",
    "\n",
    "    # Initialize a counter\n",
    "    i =0\n",
    "    while True:\n",
    "#         np.random.shuffle(indices)\n",
    "        # Get the next batch\n",
    "        count = 0\n",
    "        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n",
    "        for j, idx in enumerate(next_batch):\n",
    "            img_name = data.iloc[idx]['image']\n",
    "            label = data.iloc[idx]['label']\n",
    "#             print(\"IMG-NAME: \", str(img_name).split(\"/\")[-1])\n",
    "            # one hot encoding\n",
    "            encoded_label = to_categorical(label, num_classes=2)\n",
    "            # read the image and resize\n",
    "            img = cv2.imread(str(img_name))\n",
    "            img = cv2.resize(img, (224,224))\n",
    "\n",
    "            # check if it's grayscale\n",
    "            if img.shape[2]==1:\n",
    "                img = np.dstack([img, img, img])\n",
    "\n",
    "            # cv2 reads in BGR mode by default\n",
    "            orig_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            # normalize the image pixels\n",
    "            orig_img = img.astype(np.float32)/255.\n",
    "\n",
    "            batch_data[count] = orig_img\n",
    "            batch_labels[count] = encoded_label\n",
    "\n",
    "\n",
    "#             count+=1\n",
    "            # generating more samples of the undersampled class\n",
    "            if augment:\n",
    "                if label==0 and count < batch_size-2:\n",
    "                    aug_img1 = seq.augment_image(img)\n",
    "                    aug_img2 = seq.augment_image(img)\n",
    "                    aug_img1 = cv2.cvtColor(aug_img1, cv2.COLOR_BGR2RGB)\n",
    "                    aug_img2 = cv2.cvtColor(aug_img2, cv2.COLOR_BGR2RGB)\n",
    "                    aug_img1 = aug_img1.astype(np.float32)/255.\n",
    "                    aug_img2 = aug_img2.astype(np.float32)/255.\n",
    "\n",
    "                    batch_data[count+1] = aug_img1\n",
    "                    batch_labels[count+1] = encoded_label\n",
    "                    batch_data[count+2] = aug_img2\n",
    "                    batch_labels[count+2] = encoded_label\n",
    "                    count +=2\n",
    "\n",
    "                else:\n",
    "                    count+=1\n",
    "            else:\n",
    "                count+=1\n",
    "\n",
    "            if count==batch_size:\n",
    "                break\n",
    "\n",
    "        i+=1\n",
    "        yield (batch_data, batch_labels)\n",
    "\n",
    "        if i>=steps:\n",
    "            i=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a =  data_gen(data=train_data, batch_size=16)\n",
    "# for x, y in a:\n",
    "#     for img, lab in zip(x,y):\n",
    "#         plt.title(lab)\n",
    "#         plt.imshow(img, cmap='gray')\n",
    "#         plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_img = Input(shape=(224,224,3), name='ImageInput')\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_1')(input_img)\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool1')(x)\n",
    "\n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_1')(x)\n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool2')(x)\n",
    "\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_1')(x)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool3')(x)\n",
    "\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_1')(x)\n",
    "    x = BatchNormalization(name='bn3')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_2')(x)\n",
    "    x = BatchNormalization(name='bn4')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool4')(x)\n",
    "\n",
    "    # x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv5_1')(x)\n",
    "    # x = BatchNormalization(name='bn5')(x)\n",
    "    # x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv5_2')(x)\n",
    "    # x = BatchNormalization(name='bn6')(x)\n",
    "    # x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv5_3')(x)\n",
    "    # x = MaxPooling2D((2,2), name='pool5')(x)\n",
    "\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.7, name='dropout1')(x)\n",
    "    x = Dense(512, activation='relu', name='fc2')(x)\n",
    "    x = Dropout(0.5, name='dropout2')(x)\n",
    "    x = Dense(2, activation='softmax', name='fc3')(x)\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model =  build_model()\n",
    "    # opt = RMSprop(lr=1e-4, clipnorm=1.)\n",
    "    opt = Adam(lr=1e-06, amsgrad=True, clipnorm=1.)\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC()],optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ImageInput (InputLayer)      [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "Conv1_1 (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "Conv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "Conv2_1 (SeparableConv2D)    (None, 112, 112, 128)     8896      \n",
      "_________________________________________________________________\n",
      "Conv2_2 (SeparableConv2D)    (None, 112, 112, 128)     17664     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "Conv3_1 (SeparableConv2D)    (None, 56, 56, 256)       34176     \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Conv3_2 (SeparableConv2D)    (None, 56, 56, 256)       68096     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Conv3_3 (SeparableConv2D)    (None, 56, 56, 256)       68096     \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "Conv4_1 (SeparableConv2D)    (None, 28, 28, 512)       133888    \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv4_2 (SeparableConv2D)    (None, 28, 28, 512)       267264    \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv4_3 (SeparableConv2D)    (None, 28, 28, 512)       267264    \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 104,197,506\n",
      "Trainable params: 104,194,434\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with strategy.scope():\n",
    "#     # Open the VGG16 weight file\n",
    "#     f = h5py.File('/data/user/tr27p/Courses/CS765-DeepLearning/FinalProject/Chest_X-Ray_Images_Pneumonia/Data/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', 'r')\n",
    "\n",
    "#     # Select the layers for which you want to set weight.\n",
    "\n",
    "#     w,b = f['block1_conv1']['block1_conv1_W_1:0'], f['block1_conv1']['block1_conv1_b_1:0']\n",
    "#     model.layers[1].set_weights = [w,b]\n",
    "\n",
    "#     w,b = f['block1_conv2']['block1_conv2_W_1:0'], f['block1_conv2']['block1_conv2_b_1:0']\n",
    "#     model.layers[2].set_weights = [w,b]\n",
    "\n",
    "#     w,b = f['block2_conv1']['block2_conv1_W_1:0'], f['block2_conv1']['block2_conv1_b_1:0']\n",
    "#     model.layers[4].set_weights = [w,b]\n",
    "\n",
    "#     w,b = f['block2_conv2']['block2_conv2_W_1:0'], f['block2_conv2']['block2_conv2_b_1:0']\n",
    "#     model.layers[5].set_weights = [w,b]\n",
    "\n",
    "# f.close()\n",
    "# print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback for printing the LR at the end of each epoch.\n",
    "class PrintLR(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print('\\nLearning rate for epoch {} is {}\\n'.format(epoch + 1, model.optimizer.lr.numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "\n",
      "Number of training and validation steps: 13 and 0\n"
     ]
    }
   ],
   "source": [
    "# batch_size = 16\n",
    "nb_epochs = 40\n",
    "BUFFER_SIZE = len(train_data)\n",
    "\n",
    "BATCH_SIZE_PER_REPLICA = 100\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "batch_size = BATCH_SIZE\n",
    "\n",
    "callbacks = [\n",
    "#     tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "    ReduceLROnPlateau(monitor='val_auc', factor=.3, patience=10, verbose=1, mode='max'),\n",
    "    # EarlyStopping(  monitor='val_loss', min_delta=1e-3, patience=5, verbose=1,\n",
    "    #                 mode='auto', baseline=None, restore_best_weights=True),\n",
    "    ModelCheckpoint(filepath='/data/user/tr27p/Courses/CS765-DeepLearning/FinalProject/Chest_X-Ray_Images_Pneumonia/Python/best_model_todate_python/'+FileTime+'/',\n",
    "                    monitor='val_auc', verbose=1,\n",
    "                    save_best_only=True, save_weights_only=True),\n",
    "    PrintLR()\n",
    "]\n",
    "\n",
    "# Get a train data generator\n",
    "train_data_gen = data_gen(data=train_data, batch_size=batch_size)\n",
    "\n",
    "# Get a valid data generator\n",
    "val_data_gen = data_gen(data=valid_data, batch_size=batch_size)\n",
    "\n",
    "# Define the number of training steps\n",
    "nb_train_steps = train_data.shape[0]//batch_size\n",
    "\n",
    "# Define the number of validation steps\n",
    "nb_valid_steps = valid_data.shape[0]//batch_size\n",
    "\n",
    "print(\"#--#--\"*10,\"\\n\\nNumber of training and validation steps: {} and {}\".format(nb_train_steps, nb_valid_steps))#len(valid_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      " BATCH_SIZE_PER_REPLICA =  100 \n",
      " BATCH_SIZE =  400 \n",
      " EPOCHS =  40\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--\n",
      "Optimizer :\n",
      "           name : Adam\n",
      "       clipnorm : 1.0\n",
      "  learning_rate : 1e-06\n",
      "          decay : 0.0\n",
      "         beta_1 : 0.9\n",
      "         beta_2 : 0.999\n",
      "        epsilon : 1e-07\n",
      "        amsgrad : True\n",
      "\n",
      "Reduce LR On Plateau :\n",
      "        Monitor : val_auc,\n",
      "         Factor : 0.3,\n",
      "           Mode : max,\n",
      "       Patience : 10\n"
     ]
    }
   ],
   "source": [
    "# print(\"#--#--\"*10,  \"\\n UPDATED MODEL BASED ON VGG16\")\n",
    "\n",
    "print(\"#--#--\"*10,  \"\\n BATCH_SIZE_PER_REPLICA = \", BATCH_SIZE_PER_REPLICA,\n",
    "                    \"\\n BATCH_SIZE = \", BATCH_SIZE,\n",
    "                    \"\\n EPOCHS = \", nb_epochs)\n",
    "\n",
    "def print_inventory(inventory_name, dct):\n",
    "    print('%s :' %(inventory_name))\n",
    "    for item, amount in dct.items():  # dct.iteritems() in Python 2\n",
    "        print('%15s : %s' % (item, amount))\n",
    "\n",
    "print(\"#--#--\"*10)\n",
    "print_inventory(\"Optimizer\", opt.get_config())\n",
    "# print(\"#--#--\"*10)\n",
    "# print_inventory(\"Early Stopping\", opt.get_config())\n",
    "# print(\"#--#--\"*10)\n",
    "# print_inventory(\"Reduce LR On Plateau\", opt.get_config())\n",
    "\n",
    "print('\\nReduce LR On Plateau :\\n%15s : %s,\\n%15s : %s,\\n%15s : %s,\\n%15s : %s' %  ('Monitor', callbacks[0].monitor,\n",
    "                                                                                    'Factor', callbacks[0].factor,\n",
    "                                                                                    'Mode', callbacks[0].mode,\n",
    "                                                                                    'Patience', callbacks[0].patience) )\n",
    "\n",
    "# print('\\n Early Stopping:\\n%15s : %s,\\n%15s : %s,\\n%15s : %s' %('Monitor', callbacks[1].monitor,\n",
    "#                                                                 'MinDelta', callbacks[1].min_delta,\n",
    "#                                                                 'patience', callbacks[1].patience) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightPath = '/data/user/tr27p/Courses/CS765-DeepLearning/FinalProject/Chest_X-Ray_Images_Pneumonia/Python/xray-best-model/best_model/best_model_para-tune_'+FileTime+'.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "\n",
      "weightPath:  /data/user/tr27p/Courses/CS765-DeepLearning/FinalProject/Chest_X-Ray_Images_Pneumonia/Python/xray-best-model/best_model/best_model_para-tune_04-17-2020-15-13.hdf5\n"
     ]
    }
   ],
   "source": [
    "print(\"#--#--\"*10,\"\\n\\nweightPath: \", weightPath)\n",
    "\n",
    "with strategy.scope():\n",
    "    model.load_weights(weightPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "\n",
      "Total number of test examples:  (624, 224, 224, 3)\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "\n",
      "Total number of labels: (624, 2)\n"
     ]
    }
   ],
   "source": [
    "# Preparing test data\n",
    "normal_cases_dir = test_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = test_dir / 'PNEUMONIA'\n",
    "\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "val_normal_cases_dir = val_dir / 'NORMAL'\n",
    "val_pneumonia_cases_dir = val_dir / 'PNEUMONIA'\n",
    "\n",
    "val_normal_cases = val_normal_cases_dir.glob('*.jpeg')\n",
    "val_pneumonia_cases = val_pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "train_normal_cases_dir = train_dir / 'NORMAL'\n",
    "train_pneumonia_cases_dir = train_dir / 'PNEUMONIA'\n",
    "\n",
    "train_normal_cases = train_normal_cases_dir.glob('*.jpeg')\n",
    "train_pneumonia_cases = train_pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "for img in normal_cases:\n",
    "    img = cv2.imread(str(img))\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    if img.shape[2] ==1:\n",
    "        img = np.dstack([img, img, img])\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)/255.\n",
    "    label = to_categorical(0, num_classes=2)\n",
    "    test_data.append(img)\n",
    "    test_labels.append(label)\n",
    "\n",
    "# for img in val_normal_cases:\n",
    "#     img = cv2.imread(str(img))\n",
    "#     img = cv2.resize(img, (224,224))\n",
    "#     if img.shape[2] ==1:\n",
    "#         img = np.dstack([img, img, img])\n",
    "#     else:\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     img = img.astype(np.float32)/255.\n",
    "#     label = to_categorical(0, num_classes=2)\n",
    "#     test_data.append(img)\n",
    "#     test_labels.append(label)\n",
    "    \n",
    "# for img in train_normal_cases:\n",
    "#     img = cv2.imread(str(img))\n",
    "#     img = cv2.resize(img, (224,224))\n",
    "#     if img.shape[2] ==1:\n",
    "#         img = np.dstack([img, img, img])\n",
    "#     else:\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     img = img.astype(np.float32)/255.\n",
    "#     label = to_categorical(0, num_classes=2)\n",
    "#     test_data.append(img)\n",
    "#     test_labels.append(label)\n",
    "    \n",
    "for img in pneumonia_cases:\n",
    "    img = cv2.imread(str(img))\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    if img.shape[2] ==1:\n",
    "        img = np.dstack([img, img, img])\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)/255.\n",
    "    label = to_categorical(1, num_classes=2)\n",
    "    test_data.append(img)\n",
    "    test_labels.append(label)\n",
    "\n",
    "# for img in val_pneumonia_cases:\n",
    "#     img = cv2.imread(str(img))\n",
    "#     img = cv2.resize(img, (224,224))\n",
    "#     if img.shape[2] ==1:\n",
    "#         img = np.dstack([img, img, img])\n",
    "#     else:\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     img = img.astype(np.float32)/255.\n",
    "#     label = to_categorical(1, num_classes=2)\n",
    "#     test_data.append(img)\n",
    "#     test_labels.append(label)\n",
    "    \n",
    "# for img in train_pneumonia_cases:\n",
    "#     img = cv2.imread(str(img))\n",
    "#     img = cv2.resize(img, (224,224))\n",
    "#     if img.shape[2] ==1:\n",
    "#         img = np.dstack([img, img, img])\n",
    "#     else:\n",
    "#         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     img = img.astype(np.float32)/255.\n",
    "#     label = to_categorical(1, num_classes=2)\n",
    "#     test_data.append(img)\n",
    "#     test_labels.append(label)\n",
    "    \n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(\"#--#--\"*10,\"\\n\\nTotal number of test examples: \", test_data.shape)\n",
    "print(\"#--#--\"*10,\"\\n\\nTotal number of labels:\", test_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 25s 41ms/sample - loss: 0.5299 - accuracy: 0.7949 - auc: 0.8891\n",
      "Loss on test set:  0.5299454919802837\n",
      "Accuracy on test set:  0.7948718\n",
      "AUC on test set:  0.8890866\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on test dataset\n",
    "with strategy.scope():\n",
    "    test_loss, test_score, test_auc = model.evaluate(test_data, test_labels, batch_size=batch_size)\n",
    "print(\"Loss on test set: \", test_loss)\n",
    "print(\"Accuracy on test set: \", test_score)\n",
    "print(\"AUC on test set: \", test_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "\n",
      " (624,)\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "\n",
      " (624,)\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "with strategy.scope():\n",
    "    preds = model.predict(test_data, batch_size=batch_size)\n",
    "preds = np.argmax(preds, axis=-1)\n",
    "\n",
    "# Original labels\n",
    "orig_test_labels = np.argmax(test_labels, axis=-1)\n",
    "\n",
    "print(\"#--#--\"*10,\"\\n\\n\",orig_test_labels.shape)\n",
    "print(\"#--#--\"*10,\"\\n\\n\",preds.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAHlCAYAAADr6sZuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd7hlZX0v8O+PGXoTBIIoAkGKBkWlXLFgSYwaMIqxIIogKti7IsYCiFEUwyVyvQEs4EVBjTEKNoqASAlgQ4yQoFKUJiBdxfLeP/Y6uDmcmTkDc+bMO/P5PM9+9lrv+661fhvOOvM9q+xVrbUAAPRkudkuAABgYQkwAEB3BBgAoDsCDADQHQEGAOiOAAMAdGfubBfAzFhzrfu3v3jghrNdBiy1arYLgGXAf//4h9e31tadqk+AWUr9xQM3zOGfP3m2y4Cl1vLLOYANM+0pD13n8nn12QMBgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDozlIbYKpqz6pqVXVTVa01qW/u0Lf/LJV3r4x9po1nuxYAmE1LbYAZs2aSfWe7CPjIu96Q5z/hYdn7WTve1XbUIfvnZTs/Nq/c5Yk54PV75LZbbr6r7/ijDsueT98+L9tph1zwnW/NRsnQlQ/94+vznMdtmb2e+fi72k7/xpfz0p0fl79+2Lq55KLv32OZa6/6Rf5um43yuU8evjhLZRFYFgLMSUleV1Xrz8TKq2rFmVgvS5+/ffauef8Rx9+t7dE7PDFH/se3869fOiMP3GjTHH/UYUmSyy+9JKd/7Us58itn5v1HHJ/DD9o3f/zjH2ejbOjG0569az545Ofu1rbJZg/NAR89Oo/Ydocpl/nYB9+V7Z/w14ujPBaxZSHAHDS8/+P8BlXV9lV1SlXdVlW3V9WpVbX9pDFHV9UvqmqHqjq7qn6T5END32VVdWxV7V5Vl1TVb6rqzKrarKpWraojquqGqrq2qj5SVXPH1rtSVR1aVRcN27+mqk6oqi0X9X8MZs/Dt90hq695v7u1bfO4J2fO3NGPwkO33ibXX3tVkuSc076RJ/3dLllhhRWz/oM2ygYbbpJLfvS9xV4z9GTr7R6bNe53tysGstGmm+fBm2w25fjvnPK1PGDDjbLxQ7ZYHOWxiC0LAebqJIcn2buqNppqQFU9IskZSdZKsmeSlyRZI8kZVbX1pOFrJjk+yXFJnpHks2N9OyZ5dUanrPZIsmmSLyb5TJJbk+ya5Mgkb06y99hyKyZZPaOwtVOSVyVZKcm5M3XkiCXPN//9uGw3/CV4/bVXZ931N7irb531N8gN114zW6XBUuc3d9ye4z/+L9nj1W+b7VK4l+YueMhS4eAk+yR5b5K9puh/T5LfJfnr1tpNSVJVJye5bFjmOWNjV0vy4tbal6dYz2pJnt5au3lYx/pJDktyXmvtrcOYk6tqpyTPS/KxJBnGv3xiJVU1J8k3k1yb5IVJDl34j0xPPnvEoZkzd06esvNzRw2t3XNQLd6aYGl29OEH57l7vDIrr7rabJfCvbRMBJjW2o1V9ZEk762qg5P8dNKQHZOcOBFehmVuqaqvJHnmpLF/SHLiPDZ1zkR4GVw8vH9z0riLk0w+PfX8JG9JskVGR3kmTPvYZlXtneHIznoPeNB0F2OWnfwfx+e8M07KBz/xxVSNUso662+QX11z1V1jrr/mqtx/PQfjYFG5+MLv5dvfPCFHHHJAbrv15iy33HJZYcWVssuLXr7ghVkiLBMBZnBoktclOTDJiyb1rZ3RqabJrsnotNK461pr87qa8teT5u+cT/tKEzNV9cwkn0tyTJIDklyf5E9JvjY+bkFaa0dmdIoqm2/1yCn+hGdJc/6Z38rnP3F4PnzMf2SllVe5q/0xT35aPvi2V+Y5e7wyN153TX55xc+yxcMfPYuVwtLlsGP//Hfo0YcfnJVXWVV46cwyE2Baa7dV1QeSfCTJhyd135hkqj9v1x/67raqGShv1ySXttb2nGioquUzClYsJT7w1n1y4fln5eabbsyLnrJ1dn/N23P8UYfl97+/M/u9/HlJki233iZveO8h2fghW2bHpz8re//94zNnzty89l0HZ86cObP8CWDJ9r63vCI/PG+0jz3/SQ/Pnq/dN6uvuVY++v535OYbb8g7X7lbNt1yq3zo41+Y7VJZBJaZADP4WEYX0B40qf2MJDtV1eqttVuTpKpWz+j00emLoa5VMjo1NW73JP7FWorsd8gR92h7+j9MPhj4Z7vt86bsts+bZrIkWKq8+yNHTdn+hKfuNN/l9nytrwrr0bJwF9JdWmu/y+gU0tMmdb0vycpJTq2qf6iq5yQ5JaNgceBiKO0bSbYcbqX+66p6+7DdmxawHAAsk5apADP4VJL/GW9orV2Y5ElJbsnoOpT/l+S2JE9srf1wMdR0VJL3J3lBkhMyupX6mUlunt9CALCsqjbV7Zp0b/OtHtkO//zJs10GLLWWX25Z/PsPFq+nPHSd77bWtp2qzx4IAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDoztx5dVTVrUnaxOzw3obp1lpbY4ZrAwCY0jwDTGtt9cVZCADAdE3rFFJVPb6qXjpMr1NVm8xsWQAA87bAAFNV702yb5L9hqYVkhw7k0UBAMzPdI7A7JLk75PcniSttauSOL0EAMya6QSYO1trLcMFvVW16syWBAAwf9MJMJ+vqiOS3K+qXpHklCRHzWxZAADzNs+7kCa01g6pqqcmuSXJ5kne01o7ecYrAwCYhwUGmMGPkqyc0WmkH81cOQAACzadu5BenuS8JM9J8twk51bVXjNdGADAvEznCMzbkjyqtXZDklTV/ZOcneSTM1kYAMC8TOci3l8kuXVs/tYkV85MOQAACza/ZyG9eZj8ZZL/rKovZ3QNzLMyOqUEADAr5ncKaeLL6n46vCZ8eebKAQBYsPk9zPGAxVkIAMB0LfAi3qpaN8nbk/xVkpUm2ltrT5nBugAA5mk6F/F+JsnFSTZJckCSy5KcP4M1AQDM13QCzP1ba59I8vvW2hmttb2SPGaG6wIAmKfpfA/M74f3q6tqpyRXJXnQzJUEADB/0wkwB1XVmknekuSjSdZI8qYZrQoAYD6m8zDHE4fJm5M8eWbLAQBYsPl9kd1HM/riuim11l4/IxWxSKy+4tzsuPm6s10GLLXW2u61s10CLNPmdwTmgsVWBQDAQpjfF9kdszgLAQCYruncRg0AsEQRYACA7ggwAEB3Fhhgqmrzqjq1qi4a5h9RVe+a+dIAAKY2nSMwRyXZL8M38rbWLkyy60wWBQAwP9MJMKu01s6b1PaHmSgGAGA6phNgrq+qTTN8qV1VPTfJ1TNaFQDAfEznWUivSXJkki2r6pdJfp7kxTNaFQDAfEznWUg/S/I3VbVqkuVaa7fOfFkAAPO2wABTVe+ZNJ8kaa0dOEM1AQDM13ROId0+Nr1Skp2T/GRmygEAWLDpnEL6yPh8VR2S5CszVhEAwALcm2/iXSXJXy7qQgAApms618D8KMMt1EnmJFk3ietfAIBZM51rYHYem/5Dkmtba77IDgCYNfMNMFW1XJKvtta2Wkz1AAAs0HyvgWmt/SnJD6vqwYupHgCABZrOKaQHJPlxVZ2XsVuqW2t/P2NVAQDMx3QCzAEzXgUAwEKYToD5u9bavuMNVXVwkjNmpiQAgPmbzvfAPHWKtmcs6kIAAKZrnkdgqupVSV6d5C+r6sKxrtWTnDXThQEAzMv8TiF9NsnXk3wgyTvG2m9trd04o1UBAMzHPANMa+3mJDcneeHiKwcAYMHuzbOQAABmlQADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdmdEAU1V7VlUbe91aVT+sqtdW1dyZ3HZvquqyqjp6tusAgB4srhDxvCS/SLLGMP3RJOslec9i2n4Pdklyy2wXweKxz8v3yte/dmLWXW+9fPcHF92t79B/PiTv3PdtufLqX2WdddaZpQqhPyuuMDenfOKNWWGFuZk7Z06+dMr3c9C/fi2nfOKNWW3VlZIk6629ei646LI8/81HJUmesM1m+fDb/iHLz52TG266LX/78sNm8yOwEBZXgPlBa+3SYfqkqnpIkjdGgLlLa+37s10Di8/ue+yZV776tXn5Xi+5W/uVV16Zb51ycjZ88INnqTLo1+/u/EOevve/5Pbf3Jm5c5fLtz755px01n/lb172v+8ac9whL88Jp1+YJFlztZVz2Dufn2e95mO58ppfZ921Vput0rkXZusamPOTrF5V6w2nTo6tql2r6idVdXtVXVBVj5+8UFU9sapOHU5F3V5V36yqrSaNmfJUzHAKa/+x+f2Hti2H9dxeVVdU1UuH/t2r6uKquq2qTquqTSetb/mqOmjY3p3D+0FVtfzYmI2HbexTVQdW1dVVdVNVnVBVD5pf3VW1blUdUVX/XVV3VNWVVfXZqnrgwv7HZsnz+CfsmLXXXvse7W9/65vy/g98KFU1C1VB/27/zZ1JkuXnzsncuXPSWrurb7VVVswTt9s8J5w2CjAveMa2+fKpP8yV1/w6SfKrX9+2+AvmXputALNJkj8mmfhpeUKStyR5d5IXJJmT5MSqut/EAlW1U5JTh2VenGS3JKsnObOqNrwPtXwhyVeTPDvJd5N8sqr+KcmrkrwjyUuTbJHks5OWO2bo/3SSnZN8Ksm+Q/tk+yV5SJK9krwhyQ5JPrOAutZO8tth2acneVuSzZKcVVUrLdQnpAsnnvCVbLDBA/OIrbee7VKgW8stVzn3+HfkilM/mG+de3HOv+jyu/r+/ilb5/TzLsmtt/82SbLZRuvlfmuskm8e9Yac9Zm3Z7edt5+tsrkXFtcppDnDRburJ3l+kuckOaG1dsfwl+YaSR7ZWvt1klTVNRkdpfm7/Dk4HJbkjNbasyZWWlWnJflZRuHnjfeytg+31j49rO+CJM9Msk+STVprtwztD0hyWFVt1Fq7fDjq88IkB7TW9h/Wc1JV/THJ+6rqg621C8e2cXlrbbexutdN8uGq2qC1dtVURbXWLsko7EwsMyfJWUmuSPKMJF+6l5+XJdAdd9yRgz/w/pz49ZNmuxTo2p/+1PKYXT+YNVdbOZ/751fkYZs+IP/106uTJM9/+jY5+kvn3DV27pzl8uiHbphn7PPRrLzS8jn9mLfkvAsvy6VXXDdb5bMQFtcRmIuT/D7JjUk+ltHRh73G+s+ZCC+DHw3vD06SqtosyaZJPlNVcydeSe5Ick6SHe9DbV+fmBhquC7JuRPhZaz+JJk40jOxvWMnrWti/omT2r86af5un29equpVw11btyX5Q0bhJRkdEZpq/N7D6bcLfnX9r+a3apYwP/vpT3P5ZT/P9ttsnS0esnF++YtfZIftH51rrrlmtkuDLt1822/y7Qv+J3/72IclSdZec9Vs+1cb5+tn/vmi+V9ed1NOOvsnueO3d+aGm27Pd753aR6xubP0vVhcAWaXJNsl2TLJqq21l7TWbhzrH59Oa+13w+TEqZL1hvdPZBSExl87J7n/fajt15Pm75xH23g9ExcvXD1p3DWT+ifcOGl+8ue7h6p6XUZh75SMjlhtn+Qx81uutXZka23b1tq2666z7rxWzRJoq4c/PFdcdV0uufSyXHLpZXnggx6Uc877XtZff/3ZLg26sc5aq2XN1VZOkqy04vJ5yv/aIpdcdm2S5DlPfVS+fuZF+d2df7hr/AmnX5jHPWrTzJmzXFZeaflst9XGufjn/mjoxeI6hXTR2F1I98YNw/t+Gf2DPtmdY9O/TbLCeGdV3fNqyftmIpCsn+SnY+0T/9rckPtu1ySnttbeMtFQVZssgvWyBHjJi1+YM884Pddff3023fhBefd7Dsiee71stsuCrq2/zho56sDdM2e55bLccpUvnvy9u464PO9p2+SQT939FO0lP782J5/9Xzn/8/vlT39qOfpLZ991uoklXy9fJndJksuS/FVr7YMLGHt5kq0mte28iOs5Y3jfNcn7x9pfNLx/exFsY5Xc83thXroI1ssS4NPHHjff/ksuvWzxFAJLkYv+56rs8MKDp+x72ium/n6XQz99ag799KkzWRYzpIsA01prVfWaJF+uqhWSfD7J9Un+Isljk1zRWvvnYfjxGd1JdGiSE5NsnWTPRVzPj6vquCT7D9finJ3RnUXvTnLcpAt4761vJNm3qt6Z5LwkT0ny3EWwXgDoXhcBJklaa1+rqh2T/GOSjydZOaNrTs5N8rmxocdkdLHtyzK6m+jMjK7BuS+nsKayR0Z3QO2V5F1JrkpycJIDFtH6D0xyvyRvyuialzOSPG3YJgAs02r8S35YemyzzbbtrP+8YLbLgKXWWtu9drZLgKXeb3/wf77bWtt2qj5PowYAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0B0BBgDojgADAHRHgAEAuiPAAADdEWAAgO4IMABAdwQYAKA7AgwA0J1qrc12DcyAqvpVkstnuw4WyjpJrp/tImApZh/rz0attXWn6hBgYAlRVRe01rad7TpgaWUfW7o4hQQAdEeAAQC6I8DAkuPI2S4AlnL2saWIa2AAgO44AgMAdEeAgXmoqj2rqlXVTVW11qS+uUPf/rNU3r0y9pk2nu1aWDqM/UxNvG6tqh9W1Wurau5s17ckqarLquro2a5jaeGHCxZszST7JnnHbBcCS7DnJflFkjWG6Y8mWS/Je2azqCXMLklume0ilhaOwMCCnZTkdVW1/kysvKpWnIn1wmL2g9baua21k1prr0hyepI3znJNS5TW2vdbaz+d7TqWFgIMLNhBw/s/zm9QVW1fVadU1W1VdXtVnVpV208ac3RV/aKqdqiqs6vqN0k+NPRdVlXHVtXuVXVJVf2mqs6sqs2qatWqOqKqbqiqa6vqI+OH56tqpao6tKouGrZ/TVWdUFVbLur/GDBN5ydZvarWG/vZ3rWqfjLsHxdU1eMnL1RVTxz2nVuHcd+sqq0mjZnyVMzk07pVtf/QtuWwntur6oqqeunQv3tVXTzsM6dV1aaT1rd8VR00bO/O4f2gqlp+bMzGwzb2qaoDq+rq4bTzCVX1oPnVXVXrDvv1f1fVHVV1ZVV9tqoeuLD/sZdFAgws2NVJDk+yd1VtNNWAqnpEkjOSrJVkzyQvyehQ+hlVtfWk4WsmOT7JcUmekeSzY307Jnl1Rqes9kiyaZIvJvlMkluT7JrRraBvTrL32HIrJlk9o7C1U5JXJVkpybkzdeQIFmCTJH9Mctsw/4Qkb0ny7iQvSDInyYlVdb+JBapqpySnDsu8OMluGf1cn1lVG96HWr6Q5KtJnp3ku0k+WVX/lNF+8o4kL02yRe6+LybJMUP/p5PsnORTGe2bx0yxjf2SPCTJXknekGSHjPbb+Vk7yW+HZZ+e5G1JNktyVlWttFCfcFnUWvPy8prilVEQaRn9Ulo7yU1JPjn0zR369h/m/23ov9/Y8mskuTHJv4+1HT0s96wptnfZMH7NsbbXD+M/Pmns95KcNp/a5yRZJaPQ86YpPtPGs/3f12vpeI39TG0x7BdrJdkno/DyH8OYy5L8OslaY8ttOyy321jbpUlOnbT+NTJ6ftH/Hmu7LMnRU9Ry1z45zO8/tL1krG2tJH9IckOSNcbaJ/a1jYb5rSavb2h/19D+iGF+42H+jEnj3jq0b7Cgusf65yTZcFhul9n+f7ukvxyBgWlord2Y5CNJXlJVW0wxZMckJ7bWbhpb5pYkX0nyxElj/5DkxHls6pzW2s1j8xcP79+cNO7ijH7R3aWqnl9V/1lVNw3buD3Jahn9wwIz7eIkv88ohH8so6MPe431n9Na+/XY/I+G9wcnSVVtltERx88Md/nNHU6T3pHknIz2sXvr6xMTQw3XJTl32EfH60/+vF9NbO/YSeuamJ+8X3910vzdPt+8VNWrhru2bstov71i6LLfLoAAA9N3aEa/nA+com/tjE41TXZNRn/xjbuutfbHeWzj15Pm75xP+12HmKvqmUk+l+QnGR12/19Jtkvyq/FxMIN2yehnbsskq7bWXjIE/wnj02mt/W6YnPj5XG94/0RGQWj8tXOS+9+H2qbaf+a1r03Us/bwPnm/vmZS/4QbJ81P/nz3UFWvyyjsnZLkOUm2T/KYBS3HiNuoYZpaa7dV1QcyOhLz4UndNyaZ6lqT9XPPX2wz8fXXuya5tLW250TDcKHh5F+yMFMuaq1deh+Wv2F43y+jf9Anu3Ns+rdJVhjvrKpF/bM+sd+un2T8zqGJ/fyG3He7ZnTK7C0TDVW1ySJY7zLBERhYOB9L8sv8+c6kCWck2amqVp9oGKafOfTNtFUyOvw8bveMzqlDDy7J6BqRv2qtXTDF68KxsZdndI3KuJ0XcT0T++2uk9pfNLx/exFsY5WMjjCNe+kiWO8ywREYWAittd9V1YG550Ph3pfRL9BTq+rgjI6y7JvRL6ipTjktat9I8uyqOjSj62u2yeiixJvmuxQsIVprrapek+TLVbVCks9ndPHuXyR5bJIrWmv/PAw/PqM7iSZ+3rfO6GLiRVnPj6vquCT7D9finJ3RnUXvTnLcpEB1b30jyb5V9c4k5yV5SpLnLoL1LhMEGFh4n8qfb3dMkrTWLqyqJyV5f0a3WFaSc5M8sbX2w8VQ01EZXXy4V0Z3gJyf0dGfLy2GbcMi0Vr7WlXtmNF3Ln08ycoZXXNybkbXeE04JqOf95dl9PN+ZkbX4NyXU1hT2SPJzzLar96V5KokByc5YBGt/8Ak90vypoyueTkjydOGbbIAnkYNAHTHNTAAQHcEGACgOwIMANAdAQYA6I4AAwB0R4ABALojwADLpOHheamqDarq3xYw9o1VtcpCrv9JVXWPh3bOq33SmD2r6vCF3N5lVbXOwiwDPRNggKVGVS30oxNaa1e11hb07advzOhblYElhAADLPGqauOquriqjqmqC6vq3yaOiAxHHt5TVd9J8ryq2rSqvlFV3+Bm/toAAAMBSURBVK2qM6tqy2HcJlV1TlWdX1Xvm7Tui4bpOVV1SFX9aNjO66rq9Uk2SHJaVZ02jPvbYV3fq6ovVNVqQ/vThzq/k9HThRf0ubavqrOr6vvD+xZj3RsOn+OSqnrv2DIvrqrzquoHVXXEvQltsDQQYIBebJHkyNbaI5LckuTVY32/ba09vrV2fEbPqXpda22bJG/N6AGcSXJYkv/bWtsuo6+nn8reSTZJ8qhhO59prf1LRl8h/+TW2pOH0zTvSvI3rbVHJ7kgyZuraqWMHunwzCRPyNRPJ5/s4iQ7ttYeleQ9Sf5prG/7jB4c+MiMgtm2VfXQJC9I8rjW2iOT/DF/frggLFM8CwnoxZWttbOG6WMzeljlIcP855JkOBLy2CRfqKqJ5VYc3h+X5B+G6f+X0TNtJvubJP/aWvtDkrTWbpxizGOSPCzJWcM2VkhyTpItk/y8tfY/Qy3HZhSI5mfNJMdU1WYZPQB0+bG+k1trNwzr+vckj8/oiePbJDl/2PbKSa5bwDZgqSTAAL2Y/OC28fnbh/flktw0HJ2Yzjomq2mOObm19sK7NVY9chrLTva+JKe11napqo2TnD7WN9XnrSTHtNb2W8jtwFLHKSSgFw+uqh2G6Rcm+c7kAa21W5L8vKqelyQ1svXQfVaSXYfpeZ12OSnJK6tq7rD82kP7rUlWH6bPTfK4qnrIMGaVqto8o9NBm1TVpmM1LsiaSX45TO85qe+pVbV2Va2c5NlD/acmeW5VrTdRX1VtNI3twFJHgAF68ZMke1TVhUnWTvJ/5zHuRUleVlU/TPLjJM8a2t+Q5DVVdX5GwWEqH09yRZILh+V3G9qPTPL1qjqttfarjMLGcUMt5ybZsrX224xOGX11uIj38ml8pg8l+UBVnZVk8sW438noVNcPknyxtXZBa+2/Mrr+5qRh2ycnecA0tgNLnWptYY94Aixew+mVE1trW81yKcASwhEYAKA7jsAAAN1xBAYA6I4AAwB0R4ABALojwAAA3RFgAIDuCDAAQHf+P0X9mvxRltYoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the confusion matrix\n",
    "cm  = confusion_matrix(orig_test_labels, preds)\n",
    "fig = plt.figure()\n",
    "plot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
    "plt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "#plt.savefig(\"/data/user/tr27p/Courses/CS765-DeepLearning/FinalProject/Chest_X-Ray_Images_Pneumonia/Python/python_confusion-mat.png\", format='png')\n",
    "# plt.savefig('/data/user/tr27p/Courses/CS765-DeepLearning/FinalProject/Chest_X-Ray_Images_Pneumonia/Python/plots/confusion-mat/python_confusion-mat-'+FileTime+'.png', format='png')\n",
    "plt.savefig('./python_confusion-mat-'+FileTime+'.png', format='png')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "\n",
      "Recall of the model is 0.96\n",
      "Precision of the model is 0.77\n",
      "F1-score: 0.8545454545454546\n"
     ]
    }
   ],
   "source": [
    "# Calculate Precision and Recall\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "print(\"#--#--\"*10,\"\\n\\nRecall of the model is {:.2f}\".format(recall))\n",
    "print(\"Precision of the model is {:.2f}\".format(precision))\n",
    "print(\"F1-score: {}\".format(2*precision*recall/(precision+recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
