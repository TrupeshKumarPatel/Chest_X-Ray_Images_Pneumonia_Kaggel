{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.clear_all_output();\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.notebook.clear_all_output();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive namespace is empty.\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "from IPython import get_ipython\n",
    "get_ipython().magic('reset -sf')\n",
    "\n",
    "%who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.6.10 |Anaconda, Inc.| (default, Mar 23 2020, 23:13:11) \n",
      "[GCC 7.3.0]\n",
      "Version info.:  sys.version_info(major=3, minor=6, micro=10, releaselevel='final', serial=0)\n",
      "TensorFlow version:  2.1.0\n",
      "TensorFlow.Keras version :  2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import shutil\n",
    "import imgaug as aug\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mimg\n",
    "import imgaug.augmenters as iaa\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2\n",
    "# from keras import backend as K\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "os.environ['AUTOGRAPH_VERBOSITY'] = \"10\"\n",
    "tf.autograph.set_verbosity(0)\n",
    "tf.compat.v1.logging.set_verbosity(0)\n",
    "\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "print(\"Python version: \", sys.version)\n",
    "print(\"Version info.: \", sys.version_info)\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "print(\"TensorFlow.Keras version : \", tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0\n",
      "/job:localhost/replica:0/task:0/device:GPU:1 -> device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:05:00.0, compute capability: 6.0\n",
      "/job:localhost/replica:0/task:0/device:GPU:2 -> device: 2, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0\n",
      "/job:localhost/replica:0/task:0/device:GPU:3 -> device: 3, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:1 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:2 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:3 -> device: XLA_GPU device\n",
      "\n",
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--\n",
      "Number of devices: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Turn interactive plotting off\n",
    "# plt.ioff()\n",
    "# Set the seed for hash based operations in python\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# Set the numpy seed\n",
    "np.random.seed(111)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement = True\n",
    "config.gpu_options.visible_device_list='0,1,2,3'\n",
    "\n",
    "# Set the random seed in tensorflow at graph level\n",
    "tf.compat.v1.set_random_seed(111)\n",
    "\n",
    "# Set the session in tensorflow\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "# Set the session in keras\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "# strategy = tf.distribute.MirroredStrategy()\n",
    "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "\n",
    "print(\"#--#--\"*10)\n",
    "print('Number of devices: {}\\n'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())\n",
    "\n",
    "# Make the augmentation sequence deterministic\n",
    "aug.seed(111)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "File time:  04-16-2020-01-35 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "FileTime = str(datetime.datetime.now().strftime(\"%m-%d-%Y-%H-%M\"))\n",
    "print(\"#--#--\"*10, \"\\nFile time: \", FileTime, \"\\n\\n\")\n",
    "\n",
    "# Define path to the data directory\n",
    "data_dir = Path('/data/user/tr27p/Courses/CS765-DeepLearning/FinalProject/Chest_X-Ray_Images_Pneumonia/Data/new_chest_xray/')\n",
    "\n",
    "# Path to train directory (Fancy pathlib...no more os.path!!)\n",
    "train_dir = data_dir / 'train'\n",
    "\n",
    "# Path to validation directory\n",
    "val_dir = data_dir / 'val'\n",
    "\n",
    "# Path to test directory\n",
    "test_dir = data_dir / 'test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "\n",
      "                                                image  label\n",
      "0  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      0\n",
      "1  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      0\n",
      "2  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      0\n",
      "3  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      1\n",
      "4  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      1\n"
     ]
    }
   ],
   "source": [
    "# Get the path to the normal and pneumonia sub-directories\n",
    "normal_cases_dir = train_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = train_dir / 'PNEUMONIA'\n",
    "\n",
    "# Get the list of all the images\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "# An empty list. We will insert the data into this list in (img_path, label) format\n",
    "train_data = []\n",
    "\n",
    "# Go through all the normal cases. The label for these cases will be 0\n",
    "for img in sorted(normal_cases):\n",
    "    train_data.append((img,0))\n",
    "\n",
    "# Go through all the pneumonia cases. The label for these cases will be 1\n",
    "for img in sorted(pneumonia_cases):\n",
    "    train_data.append((img, 1))\n",
    "\n",
    "# Get a pandas dataframe from the data we have in our list\n",
    "train_data = pd.DataFrame(train_data, columns=['image', 'label'],index=None)\n",
    "\n",
    "# Shuffle the data\n",
    "train_data = train_data.sample(random_state=111, frac=1.).reset_index(drop=True)\n",
    "# train_data = train_data.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "# How the dataframe looks like?\n",
    "print(\"#--#--\"*10,\"\\n\\n\",train_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    19375\n",
      "0    14751\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get the counts for each class\n",
    "cases_count = train_data['label'].value_counts()\n",
    "print(cases_count)\n",
    "\n",
    "# Plot the results\n",
    "# plt.figure(figsize=(10,8))\n",
    "# sns.barplot(x=cases_count.index, y= cases_count.values)\n",
    "# plt.title('Number of cases', fontsize=14)\n",
    "# plt.xlabel('Case type', fontsize=12)\n",
    "# plt.ylabel('Count', fontsize=12)\n",
    "# plt.xticks(range(len(cases_count.index)), ['Normal(0)', 'Pneumonia(1)'])\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get few samples for both the classes\n",
    "pneumonia_samples = (train_data[train_data['label']==1]['image'].iloc[:5]).tolist()\n",
    "normal_samples = (train_data[train_data['label']==0]['image'].iloc[:5]).tolist()\n",
    "\n",
    "# Concat the data in a single list and del the above two list\n",
    "samples = pneumonia_samples + normal_samples\n",
    "del pneumonia_samples, normal_samples\n",
    "\n",
    "# Plot the data\n",
    "# f, ax = plt.subplots(2,5, figsize=(30,10))\n",
    "# for i in range(10):\n",
    "#     img = imread(samples[i])\n",
    "#     ax[i//5, i%5].imshow(img, cmap='gray')\n",
    "#     if i<5:\n",
    "#         ax[i//5, i%5].set_title(\"Pneumonia\")\n",
    "#     else:\n",
    "#         ax[i//5, i%5].set_title(\"Normal\")\n",
    "#     ax[i//5, i%5].axis('off')\n",
    "#     ax[i//5, i%5].set_aspect('auto')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "\n",
      "                                                image  label\n",
      "0  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      1\n",
      "1  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      1\n",
      "2  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      0\n",
      "3  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      1\n",
      "4  /data/user/tr27p/Courses/CS765-DeepLearning/Fi...      0\n"
     ]
    }
   ],
   "source": [
    "# Get the path to the sub-directories\n",
    "normal_cases_dir = val_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = val_dir / 'PNEUMONIA'\n",
    "\n",
    "# Get the list of all the images\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "# List that are going to contain validation images data and the corresponding labels\n",
    "# An empty list. We will insert the data into this list in (img_path, label) format\n",
    "valid_data = []\n",
    "\n",
    "\n",
    "# Go through all the normal cases. The label for these cases will be 0\n",
    "for img in sorted(normal_cases):\n",
    "    valid_data.append((img,0))\n",
    "\n",
    "# Go through all the pneumonia cases. The label for these cases will be 1\n",
    "for img in sorted(pneumonia_cases):\n",
    "    valid_data.append((img, 1))\n",
    "\n",
    "# Get a pandas dataframe from the data we have in our list\n",
    "valid_data = pd.DataFrame(valid_data, columns=['image', 'label'],index=None)\n",
    "\n",
    "# Shuffle the data\n",
    "valid_data = valid_data.sample(random_state=111, frac=1.).reset_index(drop=True)\n",
    "# train_data = train_data.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "# How the dataframe looks like?\n",
    "print(\"#--#--\"*10,\"\\n\\n\",valid_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation sequence\n",
    "seq = iaa.OneOf([\n",
    "    iaa.Fliplr(), # horizontal flips\n",
    "    iaa.Affine(rotate=20), # roatation\n",
    "    iaa.Multiply((1.2, 1.5))]) #random brightness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(data, batch_size, augment=False):\n",
    "    # Get total number of samples in the data\n",
    "    n = len(data)\n",
    "    steps = n//batch_size\n",
    "\n",
    "    # Define two numpy arrays for containing batch data and labels\n",
    "    batch_data = np.zeros((batch_size, 224, 224, 3), dtype=np.float32)\n",
    "    batch_labels = np.zeros((batch_size,2), dtype=np.float32)\n",
    "\n",
    "    # Get a numpy array of all the indices of the input data\n",
    "    indices = np.arange(n)\n",
    "\n",
    "    # Initialize a counter\n",
    "    i =0\n",
    "    while True:\n",
    "#         np.random.shuffle(indices)\n",
    "        # Get the next batch\n",
    "        count = 0\n",
    "        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n",
    "        for j, idx in enumerate(next_batch):\n",
    "            img_name = data.iloc[idx]['image']\n",
    "            label = data.iloc[idx]['label']\n",
    "#             print(\"IMG-NAME: \", str(img_name).split(\"/\")[-1])\n",
    "            # one hot encoding\n",
    "            encoded_label = to_categorical(label, num_classes=2)\n",
    "            # read the image and resize\n",
    "            img = cv2.imread(str(img_name))\n",
    "            img = cv2.resize(img, (224,224))\n",
    "\n",
    "            # check if it's grayscale\n",
    "            if img.shape[2]==1:\n",
    "                img = np.dstack([img, img, img])\n",
    "\n",
    "            # cv2 reads in BGR mode by default\n",
    "            orig_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            # normalize the image pixels\n",
    "            orig_img = img.astype(np.float32)/255.\n",
    "\n",
    "            batch_data[count] = orig_img\n",
    "            batch_labels[count] = encoded_label\n",
    "\n",
    "\n",
    "#             count+=1\n",
    "            # generating more samples of the undersampled class\n",
    "            if augment:\n",
    "                if label==0 and count < batch_size-2:\n",
    "                    aug_img1 = seq.augment_image(img)\n",
    "                    aug_img2 = seq.augment_image(img)\n",
    "                    aug_img1 = cv2.cvtColor(aug_img1, cv2.COLOR_BGR2RGB)\n",
    "                    aug_img2 = cv2.cvtColor(aug_img2, cv2.COLOR_BGR2RGB)\n",
    "                    aug_img1 = aug_img1.astype(np.float32)/255.\n",
    "                    aug_img2 = aug_img2.astype(np.float32)/255.\n",
    "\n",
    "                    batch_data[count+1] = aug_img1\n",
    "                    batch_labels[count+1] = encoded_label\n",
    "                    batch_data[count+2] = aug_img2\n",
    "                    batch_labels[count+2] = encoded_label\n",
    "                    count +=2\n",
    "\n",
    "                else:\n",
    "                    count+=1\n",
    "            else:\n",
    "                count+=1\n",
    "\n",
    "            if count==batch_size:\n",
    "                break\n",
    "\n",
    "        i+=1\n",
    "        yield (batch_data, batch_labels)\n",
    "\n",
    "        if i>=steps:\n",
    "            i=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a =  data_gen(data=train_data, batch_size=16)\n",
    "# for x, y in a:\n",
    "#     for img, lab in zip(x,y):\n",
    "#         plt.title(lab)\n",
    "#         plt.imshow(img, cmap='gray')\n",
    "#         plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_img = Input(shape=(224,224,3), name='ImageInput')\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_1')(input_img)\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool1')(x)\n",
    "\n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_1')(x)\n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool2')(x)\n",
    "\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_1')(x)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool3')(x)\n",
    "\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_1')(x)\n",
    "    x = BatchNormalization(name='bn3')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_2')(x)\n",
    "    x = BatchNormalization(name='bn4')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool4')(x)\n",
    "\n",
    "    # x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv5_1')(x)\n",
    "    # x = BatchNormalization(name='bn5')(x)\n",
    "    # x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv5_2')(x)\n",
    "    # x = BatchNormalization(name='bn6')(x)\n",
    "    # x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv5_3')(x)\n",
    "    # x = MaxPooling2D((2,2), name='pool5')(x)\n",
    "\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.7, name='dropout1')(x)\n",
    "    x = Dense(512, activation='relu', name='fc2')(x)\n",
    "    x = Dropout(0.5, name='dropout2')(x)\n",
    "    x = Dense(2, activation='softmax', name='fc3')(x)\n",
    "\n",
    "    model = Model(inputs=input_img, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model =  build_model()\n",
    "    # opt = RMSprop(lr=1e-4, clipnorm=1.)\n",
    "    opt = Adam(lr=1e-4, amsgrad=True, clipnorm=1.)\n",
    "    model.compile(loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC()],optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ImageInput (InputLayer)      [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "Conv1_1 (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "Conv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "Conv2_1 (SeparableConv2D)    (None, 112, 112, 128)     8896      \n",
      "_________________________________________________________________\n",
      "Conv2_2 (SeparableConv2D)    (None, 112, 112, 128)     17664     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "Conv3_1 (SeparableConv2D)    (None, 56, 56, 256)       34176     \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Conv3_2 (SeparableConv2D)    (None, 56, 56, 256)       68096     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Conv3_3 (SeparableConv2D)    (None, 56, 56, 256)       68096     \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "Conv4_1 (SeparableConv2D)    (None, 28, 28, 512)       133888    \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv4_2 (SeparableConv2D)    (None, 28, 28, 512)       267264    \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv4_3 (SeparableConv2D)    (None, 28, 28, 512)       267264    \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 104,197,506\n",
      "Trainable params: 104,194,434\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ImageInput (InputLayer)      [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "Conv1_1 (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "Conv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "Conv2_1 (SeparableConv2D)    (None, 112, 112, 128)     8896      \n",
      "_________________________________________________________________\n",
      "Conv2_2 (SeparableConv2D)    (None, 112, 112, 128)     17664     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "Conv3_1 (SeparableConv2D)    (None, 56, 56, 256)       34176     \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Conv3_2 (SeparableConv2D)    (None, 56, 56, 256)       68096     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Conv3_3 (SeparableConv2D)    (None, 56, 56, 256)       68096     \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "Conv4_1 (SeparableConv2D)    (None, 28, 28, 512)       133888    \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv4_2 (SeparableConv2D)    (None, 28, 28, 512)       267264    \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv4_3 (SeparableConv2D)    (None, 28, 28, 512)       267264    \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 104,197,506\n",
      "Trainable params: 104,194,434\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    # Open the VGG16 weight file\n",
    "    f = h5py.File('/data/user/tr27p/Courses/CS765-DeepLearning/FinalProject/Chest_X-Ray_Images_Pneumonia/Data/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', 'r')\n",
    "\n",
    "    # Select the layers for which you want to set weight.\n",
    "\n",
    "    w,b = f['block1_conv1']['block1_conv1_W_1:0'], f['block1_conv1']['block1_conv1_b_1:0']\n",
    "    model.layers[1].set_weights = [w,b]\n",
    "\n",
    "    w,b = f['block1_conv2']['block1_conv2_W_1:0'], f['block1_conv2']['block1_conv2_b_1:0']\n",
    "    model.layers[2].set_weights = [w,b]\n",
    "\n",
    "    w,b = f['block2_conv1']['block2_conv1_W_1:0'], f['block2_conv1']['block2_conv1_b_1:0']\n",
    "    model.layers[4].set_weights = [w,b]\n",
    "\n",
    "    w,b = f['block2_conv2']['block2_conv2_W_1:0'], f['block2_conv2']['block2_conv2_b_1:0']\n",
    "    model.layers[5].set_weights = [w,b]\n",
    "\n",
    "f.close()\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback for printing the LR at the end of each epoch.\n",
    "class PrintLR(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print('\\nLearning rate for epoch {} is {}\\n'.format(epoch + 1, model.optimizer.lr.numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#--#-- \n",
      "\n",
      "Number of training and validation steps: 106 and 15\n"
     ]
    }
   ],
   "source": [
    "# batch_size = 16\n",
    "nb_epochs = 20\n",
    "BUFFER_SIZE = len(train_data)\n",
    "\n",
    "BATCH_SIZE_PER_REPLICA = 80\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "batch_size = BATCH_SIZE\n",
    "\n",
    "callbacks = [\n",
    "#     tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "    ReduceLROnPlateau(monitor='val_auc', factor=.5, patience=3, verbose=1, mode='max'),\n",
    "    # EarlyStopping(  monitor='val_loss', min_delta=1e-3, patience=5, verbose=1,\n",
    "    #                 mode='auto', baseline=None, restore_best_weights=True),\n",
    "    ModelCheckpoint(filepath='/data/user/tr27p/Courses/CS765-DeepLearning/FinalProject/Chest_X-Ray_Images_Pneumonia/Python/best_model_todate_python/'+FileTime+'/',\n",
    "                    monitor='val_auc', verbose=1,\n",
    "                    save_best_only=True, save_weights_only=True),\n",
    "    PrintLR()\n",
    "]\n",
    "\n",
    "# Get a train data generator\n",
    "train_data_gen = data_gen(data=train_data, batch_size=batch_size)\n",
    "\n",
    "# Get a valid data generator\n",
    "val_data_gen = data_gen(data=valid_data, batch_size=batch_size)\n",
    "\n",
    "# Define the number of training steps\n",
    "nb_train_steps = train_data.shape[0]//batch_size\n",
    "\n",
    "# Define the number of validation steps\n",
    "nb_valid_steps = valid_data.shape[0]//batch_size\n",
    "\n",
    "print(\"#--#--\"*10,\"\\n\\nNumber of training and validation steps: {} and {}\".format(nb_train_steps, nb_valid_steps))#len(valid_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "`generator` must be callable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a13fa16a51d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m                                          \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                          output_shapes=(tf.TensorShape([None]),\n\u001b[0;32m----> 4\u001b[0;31m                                                         tf.TensorShape([None]))\n\u001b[0m\u001b[1;32m      5\u001b[0m                                                         )\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/user/tr27p/.conda/envs/cs765/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_generator\u001b[0;34m(generator, output_types, output_shapes, args)\u001b[0m\n\u001b[1;32m    736\u001b[0m     \"\"\"\n\u001b[1;32m    737\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`generator` must be callable.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m       output_shapes = nest.map_structure(\n",
      "\u001b[0;31mTypeError\u001b[0m: `generator` must be callable."
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(train_data_gen,\n",
    "                                         output_types=(tf.float32, tf.float32),\n",
    "                                         output_shapes=(tf.TensorShape([None]),\n",
    "                                                        tf.TensorShape([None]))\n",
    "                                                        )\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_generator(val_data_gen,\n",
    "                                         output_types=(tf.float32, tf.float32),\n",
    "                                         output_shapes=(tf.TensorShape([None]),\n",
    "                                                        tf.TensorShape([]))\n",
    "                                                        )\n",
    "\n",
    "train_dist_dataset = strategy.experimental_distribute_datasets_from_function(train_dataset)\n",
    "val_dist_dataset = strategy.experimental_distribute_datasets_from_function(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"#--#--\"*10,  \"\\n UPDATED MODEL BASED ON VGG16\")\n",
    "\n",
    "print(\"#--#--\"*10,  \"\\n BATCH_SIZE_PER_REPLICA = \", BATCH_SIZE_PER_REPLICA,\n",
    "                    \"\\n BATCH_SIZE = \", BATCH_SIZE,\n",
    "                    \"\\n EPOCHS = \", nb_epochs)\n",
    "\n",
    "def print_inventory(inventory_name, dct):\n",
    "    print('%s :' %(inventory_name))\n",
    "    for item, amount in dct.items():  # dct.iteritems() in Python 2\n",
    "        print('%15s : %s' % (item, amount))\n",
    "\n",
    "print(\"#--#--\"*10)\n",
    "print_inventory(\"Optimizer\", opt.get_config())\n",
    "# print(\"#--#--\"*10)\n",
    "# print_inventory(\"Early Stopping\", opt.get_config())\n",
    "# print(\"#--#--\"*10)\n",
    "# print_inventory(\"Reduce LR On Plateau\", opt.get_config())\n",
    "\n",
    "print('\\nReduce LR On Plateau :\\n%15s : %s,\\n%15s : %s,\\n%15s : %s,\\n%15s : %s' %  ('Monitor', callbacks[0].monitor,\n",
    "                                                                                    'Factor', callbacks[0].factor,\n",
    "                                                                                    'Mode', callbacks[0].mode,\n",
    "                                                                                    'Patience', callbacks[0].patience) )\n",
    "\n",
    "# print('\\n Early Stopping:\\n%15s : %s,\\n%15s : %s,\\n%15s : %s' %('Monitor', callbacks[1].monitor,\n",
    "#                                                                 'MinDelta', callbacks[1].min_delta,\n",
    "#                                                                 'patience', callbacks[1].patience) )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
